{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import cnn_tester\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from lib import datasets\n",
    "\n",
    "from os.path import join as opj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf7f7b",
   "metadata": {},
   "source": [
    "# Hyperparameters validation - Computation of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "data_dir = '../data/preprocessed/BrainPedia_dataset'\n",
    "out_dir = '../data/derived/BrainPedia_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific setup\n",
    "preprocess_type = 'resampled_masked_normalized'\n",
    "\n",
    "# Training setup \n",
    "train_subset ='bp_dataset'\n",
    "lr_to_test = ['1e-04', '1e-05']\n",
    "model_to_test = ['model_cnn_4layers', 'model_cnn_5layers']\n",
    "init_to_test = ['retrain_no', 'retrain_all']\n",
    "batch_to_test = [32, 64]\n",
    "epochs_to_test = [500, 1000]\n",
    "\n",
    "# Validation setup\n",
    "valid_id_file = opj(data_dir, f'valid_{train_subset}.txt')\n",
    "label_file = opj(data_dir, f'{train_subset}_labels.csv')\n",
    "label_col = 'tags'\n",
    "label_filelist = pd.read_csv(opj(data_dir, \n",
    "                                 f'{train_subset}_labels.csv'))\n",
    "\n",
    "label_list = sorted(np.unique(label_filelist[label_col]))\n",
    "\n",
    "valid_set = datasets.ClassifDataset(opj(data_dir, preprocess_type), valid_id_file, label_file, label_col,\n",
    "                                  label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_list = []\n",
    "model_list = []\n",
    "arch_list = []\n",
    "epochs_list = []\n",
    "batch_list = []\n",
    "lr_list = []\n",
    "prec_list = []\n",
    "rec_list = []\n",
    "\n",
    "if not os.path.exists('../figures/validation_model_bp.csv'):\n",
    "    print('Calculating validation performance...')\n",
    "    for model in model_to_test:\n",
    "        for init in init_to_test:\n",
    "            for epochs in epochs_to_test:\n",
    "                for batch in batch_to_test:\n",
    "                    for lr in lr_to_test:\n",
    "                        model_list.append(init)\n",
    "                        arch_list.append(model)\n",
    "                        batch_list.append(batch)\n",
    "                        epochs_list.append(epochs)\n",
    "                        lr_list.append(lr)\n",
    "\n",
    "                        # Model to test\n",
    "                        parameter_file = opj(out_dir, f\"{train_subset}_maps_classification_tags_{model}_\" + \\\n",
    "                                f\"{init}_{preprocess_type}_epochs_{epochs}_batch_size_{batch}_lr_{lr}\", \n",
    "                                             \"model_final.pt\")\n",
    "\n",
    "                        acc, f1, prec, rec, acc_class = cnn_tester.tester(valid_set, \n",
    "                                                                          parameter_file) # Compute results\n",
    "\n",
    "                        accuracies.append(acc)\n",
    "                        f1_list.append(f1)\n",
    "                        prec_list.append(prec)\n",
    "                        rec_list.append(rec)\n",
    "                    \n",
    "    # Creation of dataframe with results\n",
    "    init_list = ['Default algorithm' if i == 'retrain_no' else 'Pre-trained CAE' for i in model_list]\n",
    "\n",
    "    arch_list = ['5 layers' if i == 'model_cnn_5layers' else '4 layers' for i in arch_list]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['Accuracy']=accuracies\n",
    "    df['F1']=f1_list\n",
    "    df['Initialization']=init_list\n",
    "    df['Batch']=batch_list\n",
    "    df['Epochs']=epochs_list\n",
    "    df['Architecture']=arch_list\n",
    "    df['Precision']=prec_list\n",
    "    df['Recall']=rec_list\n",
    "    \n",
    "    df.to_csv('../figures/validation_model_bp.csv') \n",
    "\n",
    "else:\n",
    "    print('Performance already computed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3baec",
   "metadata": {},
   "source": [
    "# Hyperparameter validation - Exploration of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b0d71",
   "metadata": {},
   "source": [
    "### Table 3 - Hyperparameters chosen for each dataset and corresponding performance of the classifier on the validation set of the dataset \n",
    "\n",
    "Here, we computed the results of Table 3 for BrainPedia dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../figures/validation_model_bp.csv') \n",
    "df[df['Initialization']=='Default algorithm'].nlargest(1, ['Accuracy', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9735e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Initialization']=='Pre-trained CAE'].nlargest(1, ['Accuracy', 'F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d936cbd",
   "metadata": {},
   "source": [
    "# Test models with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52618f",
   "metadata": {},
   "source": [
    "## Small BrainPedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9658c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../figures/comparison_small_bp.csv'):\n",
    "    accuracies = []\n",
    "    f1_list = []\n",
    "    model_list = []\n",
    "\n",
    "    sets = 'small_bp_dataset'\n",
    "    train_id_file = opj(data_dir, f'train_{sets}.txt')\n",
    "    test_id_file = opj(data_dir, f'test_{sets}.txt')\n",
    "    label_file = opj(data_dir, f'{sets}_labels.csv')\n",
    "    label_col = 'tags'\n",
    "    label_filelist = pd.read_csv(opj('../data/preprocessed/BrainPedia_dataset', \n",
    "                                     f'small_bp_dataset_labels.csv'))\n",
    "    label_list = sorted(np.unique(label_filelist['tags']))\n",
    "    train_set = datasets.ClassifDataset(opj(data_dir, preprocess_type), train_id_file, label_file, label_col, \n",
    "                                       label_list)\n",
    "    test_set = datasets.ClassifDataset(opj(data_dir, preprocess_type), test_id_file, label_file, label_col, \n",
    "                                      label_list)\n",
    "\n",
    "    lr = '1e-04'\n",
    "    device='cpu'\n",
    "\n",
    "    model = 'model_cnn_4layers_retrain_no'\n",
    "    epochs = 500\n",
    "    batch=64\n",
    "    lr = '1e-05'\n",
    "    model_list.append('Default algorithm')\n",
    "    parameter_file = opj(out_dir, \n",
    "     f'{sets}_maps_classification_tags_{model}_{preprocess_type}_epochs_{epochs}_batch_size_{batch}_lr_{lr}', \n",
    "                                 f'model_final.pt')\n",
    "\n",
    "    acc, f1, prec, rec, acc_class = cnn_tester.tester(test_set, parameter_file)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    model = 'model_cnn_5layers_retrain_all'\n",
    "    epochs = 500\n",
    "    batch=32\n",
    "    lr = '1e-05'\n",
    "    model_list.append('Pre-trained CAE')\n",
    "    parameter_file = opj(out_dir, \n",
    "     f'{sets}_maps_classification_tags_{model}_{preprocess_type}_epochs_{epochs}_batch_size_{batch}_lr_{lr}', \n",
    "                                 f'model_final.pt')\n",
    "\n",
    "\n",
    "    acc, f1, prec, rec, acc_class = cnn_tester.tester(test_set, parameter_file)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "\n",
    "    df_sbp = pd.DataFrame()\n",
    "    df_sbp['Accuracy']=accuracies\n",
    "    df_sbp['F1']=f1_list\n",
    "    df_sbp['Model']=model_list\n",
    "\n",
    "    df_sbp.to_csv('../figures/comparison_small_bp.csv')\n",
    "    \n",
    "else:\n",
    "    print('Performance already computed.')\n",
    "    df_sbp = pd.read_csv('../figures/comparison_small_bp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy')\n",
    "print('Default algorithm')\n",
    "print(str(round(np.mean(df_sbp['Accuracy'][df_sbp['Model']=='Default algorithm']) * 100, 1)))\n",
    "\n",
    "print('Pre-trained CAE')\n",
    "print(str(round(np.mean(df_sbp['Accuracy'][df_sbp['Model']=='Pre-trained CAE']) * 100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d8bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1-score')\n",
    "print('Default algorithm')\n",
    "print(str(round(np.mean(df_sbp['F1'][df_sbp['Model']=='Default algorithm']) * 100, 1)))\n",
    "\n",
    "print('Pre-trained CAE')\n",
    "print(str(round(np.mean(df_sbp['F1'][df_sbp['Model']=='Pre-trained CAE']) * 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f491f",
   "metadata": {},
   "source": [
    "## Large BrainPedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af335d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../figures/comparison_bp.csv'):\n",
    "    accuracies = []\n",
    "    f1_list = []\n",
    "    model_list = []\n",
    "\n",
    "    sets = 'bp_dataset'\n",
    "    train_id_file = opj(data_dir, f'train_{sets}.txt')\n",
    "    test_id_file = opj(data_dir, f'test_{sets}.txt')\n",
    "    label_file = opj(data_dir, f'{sets}_labels.csv')\n",
    "    label_col = 'tags'\n",
    "    label_filelist = pd.read_csv(opj('../data/preprocessed/BrainPedia_dataset', \n",
    "                                     f'bp_dataset_labels.csv'))\n",
    "    label_list = sorted(np.unique(label_filelist['tags']))\n",
    "    train_set = datasets.ClassifDataset(opj(data_dir, preprocess_type), train_id_file, label_file, label_col, \n",
    "                                       label_list)\n",
    "    test_set = datasets.ClassifDataset(opj(data_dir, preprocess_type), test_id_file, label_file, label_col, \n",
    "                                      label_list)\n",
    "\n",
    "    lr = '1e-04'\n",
    "    device='cpu'\n",
    "\n",
    "    model = 'model_cnn_4layers_retrain_no'\n",
    "    epochs = 500\n",
    "    batch=64\n",
    "    lr = '1e-05'\n",
    "    model_list.append('Default algorithm')\n",
    "    parameter_file = opj(out_dir, \n",
    "     f'{sets}_maps_classification_tags_{model}_{preprocess_type}_epochs_{epochs}_batch_size_{batch}_lr_{lr}', \n",
    "                                 f'model_final.pt')\n",
    "\n",
    "    acc, f1, prec, rec, acc_class = cnn_tester.tester(test_set, parameter_file)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    model = 'model_cnn_5layers_retrain_all'\n",
    "    epochs = 500\n",
    "    batch=32\n",
    "    lr = '1e-05'\n",
    "    model_list.append('Pre-trained CAE')\n",
    "    parameter_file = opj(out_dir, \n",
    "     f'{sets}_maps_classification_tags_{model}_{preprocess_type}_epochs_{epochs}_batch_size_{batch}_lr_{lr}', \n",
    "                                 f'model_final.pt')\n",
    "\n",
    "\n",
    "    acc, f1, prec, rec, acc_class = cnn_tester.tester(test_set, parameter_file)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "\n",
    "    df_bp = pd.DataFrame()\n",
    "    df_bp['Accuracy']=accuracies\n",
    "    df_bp['F1']=f1_list\n",
    "    df_bp['Model']=model_list\n",
    "\n",
    "    df_bp.to_csv('../figures/comparison_bp.csv')\n",
    "    \n",
    "else:\n",
    "    print('Performance already computed.')\n",
    "    df_bp = pd.read_csv('../figures/comparison_bp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc70bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy')\n",
    "print('Default algorithm')\n",
    "print(str(round(np.mean(df_bp['Accuracy'][df_bp['Model']=='Default algorithm']) * 100, 1)))\n",
    "\n",
    "print('Pre-trained CAE')\n",
    "print(str(round(np.mean(df_bp['Accuracy'][df_bp['Model']=='Pre-trained CAE']) * 100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1-score')\n",
    "print('Default algorithm')\n",
    "print(str(round(np.mean(df_bp['F1'][df_bp['Model']=='Default algorithm']) * 100, 1)))\n",
    "\n",
    "print('Pre-trained CAE')\n",
    "print(str(round(np.mean(df_bp['F1'][df_bp['Model']=='Pre-trained CAE']) * 100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d211d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbp = pd.read_csv('../figures/comparison_small_bp.csv')\n",
    "df_bp = pd.read_csv('../figures/comparison_bp.csv')\n",
    "\n",
    "df_sbp['Dataset'] = 'Small'\n",
    "df_bp['Dataset']='Large'\n",
    "\n",
    "df = df_sbp.append(df_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bbee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.pointplot(x=\"Dataset\", y=\"F1\", hue='Model',\n",
    "                 data=df, dodge=True, size=20, join = False, markers = 'x')\n",
    "\n",
    "ax.figure.savefig('../figures/fig7.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
